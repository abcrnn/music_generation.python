{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mThe directory '/home/cseos2g/datduyn/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mThe directory '/home/cseos2g/datduyn/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting hmmlearn\n",
      "Requirement already satisfied: scikit-learn>=0.16 in /util/opt/anaconda/4.3.14/envs/jupyterhub-root/lib/python3.6/site-packages (from hmmlearn)\n",
      "Requirement already satisfied: numpy in /util/opt/anaconda/4.3.14/envs/jupyterhub-root/lib/python3.6/site-packages (from hmmlearn)\n",
      "Installing collected packages: hmmlearn\n",
      "\u001b[31mException:\n",
      "Traceback (most recent call last):\n",
      "  File \"/util/opt/anaconda/4.3.14/envs/jupyterhub-root/lib/python3.6/site-packages/pip/basecommand.py\", line 215, in main\n",
      "    status = self.run(options, args)\n",
      "  File \"/util/opt/anaconda/4.3.14/envs/jupyterhub-root/lib/python3.6/site-packages/pip/commands/install.py\", line 342, in run\n",
      "    prefix=options.prefix_path,\n",
      "  File \"/util/opt/anaconda/4.3.14/envs/jupyterhub-root/lib/python3.6/site-packages/pip/req/req_set.py\", line 784, in install\n",
      "    **kwargs\n",
      "  File \"/util/opt/anaconda/4.3.14/envs/jupyterhub-root/lib/python3.6/site-packages/pip/req/req_install.py\", line 851, in install\n",
      "    self.move_wheel_files(self.source_dir, root=root, prefix=prefix)\n",
      "  File \"/util/opt/anaconda/4.3.14/envs/jupyterhub-root/lib/python3.6/site-packages/pip/req/req_install.py\", line 1064, in move_wheel_files\n",
      "    isolated=self.isolated,\n",
      "  File \"/util/opt/anaconda/4.3.14/envs/jupyterhub-root/lib/python3.6/site-packages/pip/wheel.py\", line 345, in move_wheel_files\n",
      "    clobber(source, lib_dir, True)\n",
      "  File \"/util/opt/anaconda/4.3.14/envs/jupyterhub-root/lib/python3.6/site-packages/pip/wheel.py\", line 316, in clobber\n",
      "    ensure_dir(destdir)\n",
      "  File \"/util/opt/anaconda/4.3.14/envs/jupyterhub-root/lib/python3.6/site-packages/pip/utils/__init__.py\", line 83, in ensure_dir\n",
      "    os.makedirs(path)\n",
      "  File \"/util/opt/anaconda/4.3.14/envs/jupyterhub-root/lib/python3.6/os.py\", line 220, in makedirs\n",
      "    mkdir(name, mode)\n",
      "OSError: [Errno 30] Read-only file system: '/util/opt/anaconda/4.3.14/envs/jupyterhub-root/lib/python3.6/site-packages/hmmlearn'\u001b[0m\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#libary dependencies\n",
    "!pip install hmmlearn #https://github.com/hmmlearn/hmmlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from hmmlearn import hmm\n",
    "from nltk import FreqDist\n",
    "import json\n",
    "# from sklearn.hmm import GaussianHMM\n",
    "\n",
    "#utils\n",
    "import pickle\n",
    "def save_model(hmm_model, save_name='./hmm_model.pkl'):\n",
    "    with open(save_name, 'wb') as output:\n",
    "        pickle.dump(hmm_model, output, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def load_model(dir_path='./'):\n",
    "    model = None\n",
    "    with open(dir_path+'/hmm_model.pkl', 'rb') as input:\n",
    "        model = pickle.load(input)\n",
    "    return model\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character base music generation with HMM\n",
    "## big pictures[2]\n",
    "\n",
    "- **Generative**\n",
    "    - Models P(x, y)\n",
    "    - prediting using Bayes rule $argmax_Y P(y\\|x)\n",
    "    - HMM\n",
    "    \n",
    "- Discriminative\n",
    "    - Models P(y|x)\n",
    "    - predicting using $argmax_y P(y\\|x)$\n",
    "    - RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Features\n",
    "Load data file contains abc notated tunes. Tunes are concatenated one after other in one file without abc notated headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = './data/jig_hornpipes_cleaned.txt'\n",
    "MODEL_DIR = '../hmm_model/04_24_19_hmm_multinomial_nvocab_components_init_emission_iter50'\n",
    "\n",
    "#make sure path to model dir exist\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(DATA_PATH, mode = 'r')\n",
    "data = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f|\"A\"ecc c2f|\"A\"ecc c2f|\"A\"ecc c2f|\"Bm\"BcB \"E7\"B2f|\n",
      "\"A\"ecc c2f|\"A\"ecc c2c/2d/2|\"D\"efe \"E7\"dcB| [1\"A\"\n"
     ]
    }
   ],
   "source": [
    "#sanity check\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters in our whole tunes database = 67\n"
     ]
    }
   ],
   "source": [
    "def get_data_info(data, save_path=None):\n",
    "    #mapping character to index\n",
    "    vocab_map = {}\n",
    "    chars = list(set(data))\n",
    "    vocab_map['char2idx'] = {ch: i for (i, ch) in enumerate(chars)}\n",
    "    vocab_map['idx2char'] = {i: ch for (i, ch) in enumerate(chars)}\n",
    "    print(\"Number of unique characters in our whole tunes database = {}\".format(len(vocab_map['char2idx']))) #87\n",
    "    \n",
    "    if save_path:\n",
    "        with open(save_path, mode = \"w+\") as f:\n",
    "            json.dump(vocab_map, f)\n",
    "        \n",
    "    n_vocab = len(vocab_map['char2idx'])\n",
    "    return vocab_map\n",
    "\n",
    "def get_train_val(data, train_frac=0.8):\n",
    "    '''\n",
    "    -data: np array of shape (N,) each cell in arrary\n",
    "    represent the character in idx\n",
    "    '''\n",
    "    n_train = int(len(data) * train_frac)\n",
    "    X_train, X_val = data[:n_train], data[n_train:len(data)]\n",
    "    return X_train, X_val\n",
    "vocab_map = get_data_info(data, save_path=os.path.join(MODEL_DIR, 'model_dictionary.json'))\n",
    "n_vocab = len(vocab_map['char2idx'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data and convert to numpy numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_characters = np.asarray([vocab_map['char2idx'][c] for c in data], dtype = np.int64)\n",
    "# Xy_train, Xy_val = get_train_val(all_characters, train_frac=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83542,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_characters.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden markov model and its variation\n",
    "#### Multinomial HMM model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model on small data\n",
    "- In this case, we only train on small dset for sannity check. We train on the full dset on crane refer to `./src/hmm_train.py` for more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fd = FreqDist(all_characters)\n",
    "frequencies = np.fromiter((fd.freq(i) for i in range(n_vocab)), dtype=np.float64)\n",
    "emission_prob = np.stack([frequencies] * n_vocab)\n",
    "\n",
    "model = hmm.MultinomialHMM(n_components=n_vocab, \n",
    "                        n_iter=2, verbose=True, tol=0.001)\n",
    "\n",
    "model.emissionprob_ = emission_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features = np.fromiter(batches, np.int64)\n",
    "features = np.array([all_characters]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -351107.4796             +nan\n",
      "         2     -251660.4069      +99447.0726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialHMM(algorithm='viterbi', init_params='ste', n_components=67,\n",
       "        n_iter=2, params='ste',\n",
       "        random_state=<mtrand.RandomState object at 0x2b46baaacd80>,\n",
       "        startprob_prior=1.0, tol=0.001, transmat_prior=1.0, verbose=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verbose True: report 3 columns. iteration number, \n",
    "# log probability of the data at the current iteration and convergence rate\n",
    "#try to overfit small data\n",
    "# lengths = [len(line) for line in batches]\n",
    "model.fit(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation: Randomly sampling from likelyhood and transition matrixc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = './hmm_model/04_24_19_hmm_multinomial_nvocab_components_init_emission_right_iter180/'\n",
    "hmm_model = load_model(dir_path=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ed3ddc 2 eFc:\"De\"|/e\n",
      "\"G|G7|2  Gd2-e=Cg aE\"g2 A\"2G| GA|c\"BGm\"\n",
      "dcEDDe|2A\n",
      " A 2dDB\"\n",
      "B2e  B||f\":eEA3B\n",
      "AEAAA:\"G| fB\"\"3|bdcA3 \"a|^ffD\"\n",
      "\"7\"7|2AGa|A|2\" Bfdd\"cf|fG\"\" D\n",
      "E \n",
      "\" \"\"\" f\"\"F|3\"b\" 3G3AG3|Bm2#edG2 -2G|f\"\"EAB2eAmg 2CAEF|\"7 f \"\"E2|Pe\"\" BA B\"ee\"BBc|3G(GDD\"AcD\"7a\"\"/\"c7\":\"V\"\n",
      "|A,2fB7F\"\" \"e\"3\n",
      "F\"||\"Bb\"2AeD7m E|FD d\"|c|2fgcA2\"e \"\n",
      "D\"B|c c ge\"fddec2\"2 dd33c\"cGAB\"BdA723\"d3cdcBeGa\n",
      "E| Daa\n",
      "2:\n",
      "G\"Bm\"Cg2Gc3Bd\"2gd/^Ad B\n"
     ]
    }
   ],
   "source": [
    "def sampling(model, vocab_map, n_samples=100):\n",
    "    X, state = model.sample(n_samples)\n",
    "    seq = ''.join(vocab_map['idx2char'][int(c)] for c in X)\n",
    "    return seq\n",
    "music_abc = sampling(model, vocab_map, n_samples=400)\n",
    "print(music_abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X: 1\n",
      "T:AbcRnn\n",
      "% abcRnn\n",
      "M:4/4\n",
      "K:Cmin\n",
      "ed3ddc 2 eFc:\"De\"|/e\n",
      "\"G|G7|2  Gd2-e=Cg aE\"g2 A\"2G| GA|c\"BGm\"\n",
      "dcEDDe|2A\n",
      " A 2dDB\"\n",
      "B2e  B||f\":eEA3B\n",
      "AEAAA:\"G| fB\"\"3|bdcA3 \"a|^ffD\"\n",
      "\"7\"7|2AGa|A|2\" Bfdd\"cf|fG\"\" D\n",
      "E \n",
      "\" \"\"\" f\"\"F|3\"b\" 3G3AG3|Bm2#edG2 -2G|f\"\"EAB2eAmg 2CAEF|\"7 f \"\"E2|Pe\"\" BA B\"ee\"BBc|3G(GDD\"AcD\"7a\"\"/\"c7\":\"V\"\n",
      "|A,2fB7F\"\" \"e\"3\n",
      "F\"||\"Bb\"2AeD7m E|FD d\"|c|2fgcA2\"e \"\n",
      "D\"B|c c ge\"fddec2\"2 dd33c\"cGAB\"BdA723\"d3cdcBeGa\n",
      "E| Daa\n",
      "2:\n",
      "G\"Bm\"Cg2Gc3Bd\"2gd/^Ad B\n"
     ]
    }
   ],
   "source": [
    "#header info: http://trillian.mit.edu/~jc/music/abc/doc/ABCtut_Headers.html#I_Key\n",
    "header = '''\n",
    "X: 1\n",
    "T:AbcRnn\n",
    "% abcRnn\n",
    "M:4/4\n",
    "K:Cmin\n",
    "'''\n",
    "music_abc = header + music_abc\n",
    "print(music_abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "music_abc = '''\n",
    "X: 1\n",
    "T:AbcRnn\n",
    "% abcRnn\n",
    "M:4/4\n",
    "K:Cmin\n",
    "DD Ddf d  eG|7Gc||gB\" /DDcdA2|cGD\"2B(c2mB\"d\"m3d2dg|eA =d\"7ee-7|2\"acfB7|g\"c\"\"  cB3Pg\" \"7GEg\"g\"\"/2|^A^bBG 2a dC D\n",
    "2\"ccB\" df|2|B\"\n",
    "\"/|2 m3mE\n",
    "cGd2 \"\"Bd2\"|/\"\"eAAd\n",
    "AgAa eGfBB2m||ACAd3 G\"\"efEEDc7  ^|:\"e7^ (\n",
    "GgmefEdA|a\"\"#fD7F2B b\"7^|\"\"]\"|bFcGgf|2B|AD c32B\"dDe\"EDE DF\"eE2EB7 62|\"GBd\n",
    "||mb\"ebC\"2\"\"|/\"AGfD2a  BfAA7\"f |Cd|dAA\"\"DBB\"B\"\"cm|\"|B|eA3eedm23 |\n",
    "EDd|Bg aDA/c| B/|\"E1|\"7\"GfG\"\"gAE7Gd2ed \"G1c\":GBE |aDA |2e7Fe\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Discussion on model prediction\n",
    "- HMM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed parsing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "abcFormat: WARNING: Could not get pitch information from note:  m2, assuming C\n",
      "abcFormat: WARNING: Could not get pitch information from note:  V, assuming C\n",
      "Traceback (most recent call last):\n",
      "  File \"/lustre/work/cseos2g/datduyn/Documents/songnet/music_generation.python/src/evaluation.py\", line 43, in save_midi\n",
      "    abcScore = converter.parse(music_abc, format='abc')\n",
      "  File \"/home/cseos2g/datduyn/.conda/envs/cs478project/lib/python3.6/site-packages/music21/converter/__init__.py\", line 1141, in parse\n",
      "    return parseData(value, number=number, format=m21Format, **keywords)\n",
      "  File \"/home/cseos2g/datduyn/.conda/envs/cs478project/lib/python3.6/site-packages/music21/converter/__init__.py\", line 1017, in parseData\n",
      "    v.parseData(dataStr, number=number, format=format, **keywords)\n",
      "  File \"/home/cseos2g/datduyn/.conda/envs/cs478project/lib/python3.6/site-packages/music21/converter/__init__.py\", line 610, in parseData\n",
      "    self.subConverter.parseData(dataStr, number=number)\n",
      "  File \"/home/cseos2g/datduyn/.conda/envs/cs478project/lib/python3.6/site-packages/music21/converter/subConverters.py\", line 1023, in parseData\n",
      "    abcFormat.translate.abcToStreamScore(abcHandler, self.stream)\n",
      "  File \"/home/cseos2g/datduyn/.conda/envs/cs478project/lib/python3.6/site-packages/music21/abcFormat/translate.py\", line 423, in abcToStreamScore\n",
      "    p = abcToStreamPart(partHandler)\n",
      "  File \"/home/cseos2g/datduyn/.conda/envs/cs478project/lib/python3.6/site-packages/music21/abcFormat/translate.py\", line 159, in abcToStreamPart\n",
      "    postTransposition, clefSet = parseTokens(mh, dst, p, useMeasures)\n",
      "  File \"/home/cseos2g/datduyn/.conda/envs/cs478project/lib/python3.6/site-packages/music21/abcFormat/translate.py\", line 292, in parseTokens\n",
      "    cs = harmony.ChordSymbol(cs_name)\n",
      "  File \"/home/cseos2g/datduyn/.conda/envs/cs478project/lib/python3.6/site-packages/music21/harmony.py\", line 1525, in __init__\n",
      "    super().__init__(figure, **keywords)\n",
      "  File \"/home/cseos2g/datduyn/.conda/envs/cs478project/lib/python3.6/site-packages/music21/harmony.py\", line 197, in __init__\n",
      "    self._parseFigure()\n",
      "  File \"/home/cseos2g/datduyn/.conda/envs/cs478project/lib/python3.6/site-packages/music21/harmony.py\", line 1802, in _parseFigure\n",
      "    self.root(pitch.Pitch(root))\n",
      "  File \"/home/cseos2g/datduyn/.conda/envs/cs478project/lib/python3.6/site-packages/music21/pitch.py\", line 1671, in __init__\n",
      "    self._setName(name) # set based on string\n",
      "  File \"/home/cseos2g/datduyn/.conda/envs/cs478project/lib/python3.6/site-packages/music21/pitch.py\", line 2504, in _setName\n",
      "    self.step = usrStr[0]\n",
      "  File \"/home/cseos2g/datduyn/.conda/envs/cs478project/lib/python3.6/site-packages/music21/pitch.py\", line 2676, in _setStep\n",
      "    raise PitchException(\"Cannot make a step out of '%s'\" % usrStr)\n",
      "music21.pitch.PitchException: Cannot make a step out of '|'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.evaluation import save_midi\n",
    "save_midi(music_abc, save_path='./midi.mid', print_trace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation: Sampling given starting seed(starting oservable sequence)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understandning model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# references\n",
    "[1] (ML 16.6) Gaussian mixture model (Mixture of Gaussians). Available at https://www.youtube.com/watch?v=Rkl30Fr2S38. 2011\n",
    "\n",
    "[2] HMM Lecture slides. available at https://www.cs.cmu.edu/~epxing/Class/10701-10s/recitation/recitation6.pdf\n",
    "\n",
    "[3] Predicting next given current state. available at https://github.com/hmmlearn/hmmlearn/issues/171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cs478project)",
   "language": "python",
   "name": "cs478project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
