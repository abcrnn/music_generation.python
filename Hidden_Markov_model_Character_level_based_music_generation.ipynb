{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mThe directory '/home/cseos2g/datduyn/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mThe directory '/home/cseos2g/datduyn/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting hmmlearn\n",
      "Requirement already satisfied: scikit-learn>=0.16 in /util/opt/anaconda/4.3.14/envs/jupyterhub-root/lib/python3.6/site-packages (from hmmlearn)\n",
      "Requirement already satisfied: numpy in /util/opt/anaconda/4.3.14/envs/jupyterhub-root/lib/python3.6/site-packages (from hmmlearn)\n",
      "Installing collected packages: hmmlearn\n",
      "\u001b[31mException:\n",
      "Traceback (most recent call last):\n",
      "  File \"/util/opt/anaconda/4.3.14/envs/jupyterhub-root/lib/python3.6/site-packages/pip/basecommand.py\", line 215, in main\n",
      "    status = self.run(options, args)\n",
      "  File \"/util/opt/anaconda/4.3.14/envs/jupyterhub-root/lib/python3.6/site-packages/pip/commands/install.py\", line 342, in run\n",
      "    prefix=options.prefix_path,\n",
      "  File \"/util/opt/anaconda/4.3.14/envs/jupyterhub-root/lib/python3.6/site-packages/pip/req/req_set.py\", line 784, in install\n",
      "    **kwargs\n",
      "  File \"/util/opt/anaconda/4.3.14/envs/jupyterhub-root/lib/python3.6/site-packages/pip/req/req_install.py\", line 851, in install\n",
      "    self.move_wheel_files(self.source_dir, root=root, prefix=prefix)\n",
      "  File \"/util/opt/anaconda/4.3.14/envs/jupyterhub-root/lib/python3.6/site-packages/pip/req/req_install.py\", line 1064, in move_wheel_files\n",
      "    isolated=self.isolated,\n",
      "  File \"/util/opt/anaconda/4.3.14/envs/jupyterhub-root/lib/python3.6/site-packages/pip/wheel.py\", line 345, in move_wheel_files\n",
      "    clobber(source, lib_dir, True)\n",
      "  File \"/util/opt/anaconda/4.3.14/envs/jupyterhub-root/lib/python3.6/site-packages/pip/wheel.py\", line 316, in clobber\n",
      "    ensure_dir(destdir)\n",
      "  File \"/util/opt/anaconda/4.3.14/envs/jupyterhub-root/lib/python3.6/site-packages/pip/utils/__init__.py\", line 83, in ensure_dir\n",
      "    os.makedirs(path)\n",
      "  File \"/util/opt/anaconda/4.3.14/envs/jupyterhub-root/lib/python3.6/os.py\", line 220, in makedirs\n",
      "    mkdir(name, mode)\n",
      "OSError: [Errno 30] Read-only file system: '/util/opt/anaconda/4.3.14/envs/jupyterhub-root/lib/python3.6/site-packages/hmmlearn'\u001b[0m\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#libary dependencies\n",
    "!pip install hmmlearn #https://github.com/hmmlearn/hmmlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from hmmlearn import hmm\n",
    "from nltk import FreqDist\n",
    "import json\n",
    "# from sklearn.hmm import GaussianHMM\n",
    "\n",
    "#utils\n",
    "import pickle\n",
    "def save_model(hmm_model, save_name='./hmm_model.pkl'):\n",
    "    with open(save_name, 'wb') as output:\n",
    "        pickle.dump(hmm_model, output, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def load_model(dir_path='./'):\n",
    "    model = None\n",
    "    with open(dir_path+'/hmm_model.pkl', 'rb') as input:\n",
    "        model = pickle.load(input)\n",
    "    return model\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character base music generation with HMM\n",
    "## big pictures[2]\n",
    "\n",
    "- **Generative**\n",
    "    - Models P(x, y)\n",
    "    - prediting using Bayes rule $argmax_Y P(y\\|x)\n",
    "    - HMM\n",
    "    \n",
    "- Discriminative\n",
    "    - Models P(y|x)\n",
    "    - predicting using $argmax_y P(y\\|x)$\n",
    "    - RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Features\n",
    "Load data file contains abc notated tunes. Tunes are concatenated one after other in one file without abc notated headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = './data/jig_hornpipes_cleaned.txt'\n",
    "MODEL_DIR = '../hmm_model/04_24_19_hmm_multinomial_nvocab_components_init_emission_iter50'\n",
    "\n",
    "#make sure path to model dir exist\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(DATA_PATH, mode = 'r')\n",
    "data = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f|\"A\"ecc c2f|\"A\"ecc c2f|\"A\"ecc c2f|\"Bm\"BcB \"E7\"B2f|\n",
      "\"A\"ecc c2f|\"A\"ecc c2c/2d/2|\"D\"efe \"E7\"dcB| [1\"A\"\n"
     ]
    }
   ],
   "source": [
    "#sanity check\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters in our whole tunes database = 67\n"
     ]
    }
   ],
   "source": [
    "def get_data_info(data, save_path=None):\n",
    "    #mapping character to index\n",
    "    vocab_map = {}\n",
    "    chars = list(set(data))\n",
    "    vocab_map['char2idx'] = {ch: i for (i, ch) in enumerate(chars)}\n",
    "    vocab_map['idx2char'] = {i: ch for (i, ch) in enumerate(chars)}\n",
    "    print(\"Number of unique characters in our whole tunes database = {}\".format(len(vocab_map['char2idx']))) #87\n",
    "    \n",
    "    if save_path:\n",
    "        with open(save_path, mode = \"w+\") as f:\n",
    "            json.dump(vocab_map, f)\n",
    "        \n",
    "    n_vocab = len(vocab_map['char2idx'])\n",
    "    return vocab_map\n",
    "\n",
    "def get_train_val(data, train_frac=0.8):\n",
    "    '''\n",
    "    -data: np array of shape (N,) each cell in arrary\n",
    "    represent the character in idx\n",
    "    '''\n",
    "    n_train = int(len(data) * train_frac)\n",
    "    X_train, X_val = data[:n_train], data[n_train:len(data)]\n",
    "    return X_train, X_val\n",
    "vocab_map = get_data_info(data, save_path=os.path.join(MODEL_DIR, 'model_dictionary.json'))\n",
    "n_vocab = len(vocab_map['char2idx'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data and convert to numpy numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_characters = np.asarray([vocab_map['char2idx'][c] for c in data], dtype = np.int64)\n",
    "# Xy_train, Xy_val = get_train_val(all_characters, train_frac=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83542,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_characters.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden markov model and its variation\n",
    "#### Multinomial HMM model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model on small data\n",
    "- In this case, we only train on small dset for sannity check. We train on the full dset on crane refer to `./src/hmm_train.py` for more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fd = FreqDist(all_characters)\n",
    "frequencies = np.fromiter((fd.freq(i) for i in range(n_vocab)), dtype=np.float64)\n",
    "emission_prob = np.stack([frequencies] * n_vocab)\n",
    "\n",
    "model = hmm.MultinomialHMM(n_components=n_vocab, \n",
    "                        n_iter=2, verbose=True, tol=0.001)\n",
    "\n",
    "model.emissionprob_ = emission_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features = np.fromiter(batches, np.int64)\n",
    "features = np.array([all_characters]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -351107.4796             +nan\n",
      "         2     -251660.4069      +99447.0726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialHMM(algorithm='viterbi', init_params='ste', n_components=67,\n",
       "        n_iter=2, params='ste',\n",
       "        random_state=<mtrand.RandomState object at 0x2b46baaacd80>,\n",
       "        startprob_prior=1.0, tol=0.001, transmat_prior=1.0, verbose=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verbose True: report 3 columns. iteration number, \n",
    "# log probability of the data at the current iteration and convergence rate\n",
    "#try to overfit small data\n",
    "# lengths = [len(line) for line in batches]\n",
    "model.fit(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation: Randomly sampling from likelyhood and transition matrixc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = './hmm_model/04_24_19_hmm_multinomial_nvocab_components_init_emission_right_iter50/'\n",
    "hmm_model = load_model(dir_path=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G2f3Efb|A m\"d\"ae\\fbc3E(cgGB\"\n",
      "\"G2\"bG\"Gd\"3c 3|\" \"|PBBegd2FDc\"g|G32\"\"\"\"2\"GM7fB3\"\"\" DG\"2\"A\"c|dA\"d^ \" \"e Be(f\"mBdAmme BeAB\"\n",
      "g3|3A\"\"|2\n",
      "7Bd|gde3\"de\n",
      "7gBe\"2 d\"E|\"2\"  Bd\" |A c A\"\\GdBB\"V cG\"\"\"2m\"EGa\"E| 2f\"G\n",
      "c cD:d\"\"\n",
      "D\"/eD7:fg\" \"2\n",
      "\"G#\"\"|g(GDg| |2(7BB3  ed\"C\"A\"GGA2\"\"\n",
      " A\"\"/f/:2 \"#g\"ceC\"\"\"\"\"G|^2F\"GB|22\n",
      "2|BBA2\"\"G\"DeGd\n",
      "DD\"m |Ge \"dGd\"7\"\"2/cdf FfF |2gcDG bB^d AAaA\n",
      "\" mg2\"A\"m\"AGGG\"\"\"3|eB  |cEde\"dBd/\"A\" \" cd\"7B|3gd\"A G\n"
     ]
    }
   ],
   "source": [
    "def sampling(model, vocab_map, n_samples=100):\n",
    "    X, state = model.sample(n_samples)\n",
    "    seq = ''.join(vocab_map['idx2char'][int(c)] for c in X)\n",
    "    return seq\n",
    "music_abc = sampling(model, vocab_map, n_samples=400)\n",
    "print(music_abc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Discussion on model prediction\n",
    "- HMM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed parsing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/lustre/work/cseos2g/datduyn/Documents/songnet/music_generation.python/src/evaluation.py\", line 43, in save_midi\n",
      "    abcScore = converter.parse(music_abc, format='abc')\n",
      "  File \"/home/cseos2g/datduyn/.conda/envs/cs478project/lib/python3.6/site-packages/music21/converter/__init__.py\", line 1141, in parse\n",
      "    return parseData(value, number=number, format=m21Format, **keywords)\n",
      "  File \"/home/cseos2g/datduyn/.conda/envs/cs478project/lib/python3.6/site-packages/music21/converter/__init__.py\", line 1017, in parseData\n",
      "    v.parseData(dataStr, number=number, format=format, **keywords)\n",
      "  File \"/home/cseos2g/datduyn/.conda/envs/cs478project/lib/python3.6/site-packages/music21/converter/__init__.py\", line 610, in parseData\n",
      "    self.subConverter.parseData(dataStr, number=number)\n",
      "  File \"/home/cseos2g/datduyn/.conda/envs/cs478project/lib/python3.6/site-packages/music21/converter/subConverters.py\", line 1016, in parseData\n",
      "    abcHandler = af.readstr(strData, number=number)\n",
      "  File \"/home/cseos2g/datduyn/.conda/envs/cs478project/lib/python3.6/site-packages/music21/abcFormat/__init__.py\", line 3054, in readstr\n",
      "    handler.process(strSrc)\n",
      "  File \"/home/cseos2g/datduyn/.conda/envs/cs478project/lib/python3.6/site-packages/music21/abcFormat/__init__.py\", line 2315, in process\n",
      "    self.tokenProcess()\n",
      "  File \"/home/cseos2g/datduyn/.conda/envs/cs478project/lib/python3.6/site-packages/music21/abcFormat/__init__.py\", line 2267, in tokenProcess\n",
      "    'tPrev: %s, t: %s, tNext: %s' % (tPrev, t, tNext))\n",
      "music21.abcFormat.ABCHandlerException: no active default note length provided for note processing. tPrev: None, t: <music21.abcFormat.ABCNote 'G'>, tNext: <music21.abcFormat.ABCNote 'D'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.evaluation import save_midi\n",
    "save_midi(music_abc, save_path='./midi.mid', print_trace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation: Sampling given starting seed(starting oservable sequence)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understandning model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# references\n",
    "[1] (ML 16.6) Gaussian mixture model (Mixture of Gaussians). Available at https://www.youtube.com/watch?v=Rkl30Fr2S38. 2011\n",
    "\n",
    "[2] HMM Lecture slides. available at https://www.cs.cmu.edu/~epxing/Class/10701-10s/recitation/recitation6.pdf\n",
    "\n",
    "[3] Predicting next given current state. available at https://github.com/hmmlearn/hmmlearn/issues/171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cs478project)",
   "language": "python",
   "name": "cs478project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
