{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Abc to midi converter\n",
    "- http://www.mandolintab.net/abcconverter.php\n",
    "\n",
    "\n",
    "## Major and Minor\n",
    "- https://www.youtube.com/watch?v=fKpUBsn_jmA\n",
    "- help create mood and atmossphere of music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "N_GRAM = 64\n",
    "MODEL_DIR = './music_model/LSTMSkipConnection_many2many_128_256_128_layers_lstm/'\n",
    "DATA_PATH = './data/jig_hornpipes_cleaned.txt'\n",
    "MODEL_TYPE = 'Default'#unuse for now\n",
    "BATCH_SIZE = 1\n",
    "SEQ_LENGTH = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_vocab 67\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(MODEL_DIR, 'model_dictionary.json')) as f:\n",
    "    vocab_map = json.load(f)\n",
    "\n",
    "n_vocab = len(vocab_map['idx2char'])\n",
    "\n",
    "print('n_vocab', n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (1, 1)               0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (1, 1, 256)          17152       input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "drop_layer1 (Dropout)           (1, 1, 256)          0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_layer0 (LSTM)              (1, 1, 128)          197120      drop_layer1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_layer1 (LSTM)              (1, 1, 256)          394240      lstm_layer0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_layer2 (LSTM)              (1, 1, 128)          197120      lstm_layer1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "rnn_concat (Concatenate)        (1, 1, 768)          0           embedding[0][0]                  \n",
      "                                                                 lstm_layer0[0][0]                \n",
      "                                                                 lstm_layer1[0][0]                \n",
      "                                                                 lstm_layer2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (1, 1, 67)           51523       rnn_concat[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 857,155\n",
      "Trainable params: 857,155\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "from models import MusicModel\n",
    "# model = MusicModel(n_vocab).TwoLayerLSTM(batch_input_shape=(BATCH_SIZE, 1))\n",
    "# model = MusicModel(n_vocab).TwoLayerLSTM(batch_input_shape=(BATCH_SIZE, SEQ_LENGTH))\n",
    "\n",
    "# model = MusicModel(n_vocab).LayersRNNGeneric(batch_input_shape=(BATCH_SIZE, SEQ_LENGTH),\n",
    "#                                             layers=['lstm', 'lstm', 'lstm'], \n",
    "#                                              layers_size=[128, 256, 128], drop_rate=0.4)\n",
    "\n",
    "# model = MusicModel(n_vocab).LSTMSkipConnection(batch_input_shape=(BATCH_SIZE, SEQ_LENGTH),\n",
    "#                                                                 layers=[128, 256, 128],\n",
    "#                                                                 emb_dim=256,drop_rate=0.2)\n",
    "\n",
    "model = MusicModel(n_vocab).LSTMSkipConnection(batch_input_shape=(BATCH_SIZE, SEQ_LENGTH),\n",
    "                    layers=[128, 256, 128],\n",
    "                    emb_dim=256,drop_rate=0.3)\n",
    "print('\\n',model.summary())\n",
    "model.load_weights(MODEL_DIR+'/model_weight/'+\"Weights_{}.h5\".format(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sequence(model, vocab_map, initial_index=0, seq_length=300):\n",
    "    sequence_index = [initial_index]\n",
    "    n_vocab = len(vocab_map['idx2char'])\n",
    "    prev_note = '\\n'\n",
    "    stop_note = ['\\n', '%']\n",
    "    for _ in range(seq_length):\n",
    "        batch = np.zeros((1, 1))\n",
    "        batch[0, 0] = sequence_index[-1]\n",
    "#         print(batch)\n",
    "        predicted_probs = model.predict_on_batch(batch).ravel()\n",
    "#         print(predicted_probs.shape)\n",
    "        \n",
    "        sample = np.random.choice(range(n_vocab), size = 1, p = predicted_probs)\n",
    "#         while vocab_map['idx2char'][str(sample[0])] in ['\\n', '%']:\n",
    "#         print(sample[0])\n",
    "#         if  vocab_map['idx2char'][str(sample[0])] in ['\\n','%', '\\\\']:\n",
    "#             continue\n",
    "        while vocab_map['idx2char'][str(sample[0])] in stop_note and prev_note in stop_note:\n",
    "            sample = np.random.choice(range(n_vocab), size = 1, p = predicted_probs)\n",
    "    \n",
    "        prev_note = vocab_map['idx2char'][str(sample[0])]\n",
    "        sequence_index.append(sample[0]) \n",
    "        \n",
    "    str_seq = seq = ''.join(vocab_map['idx2char'][str(c)] for c in sequence_index)\n",
    "    return str_seq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4|\"A\"AAA eAA|\"D\"AdA fAa|\"G\"gab g3|\"G\"bge \"D\"agf|\"E\"gfe edB|\n",
      "\"A\"A2A ABe|\"A\"ceA age|\"A7\"cea gfe|\"D\"d3 -d||\n",
      "|\n",
      "\"E7\"cde BdB|\"Em\"efe dcB|\"A\"ecA \"A\"Ace|\"D\"def \"E7\"e2=g|\"A\"aec a2:|\n",
      " [2\"A\"Ace ag=g||\n",
      "\"D\"a2f a2f|\"A\"eac A2e|\"Bm\"gfe \"B7\"fed|\"E7\"e3 e2:|\n",
      "P:B\n",
      "f/2g/2|\"A\"aec aec|\"D\"d2b a2f|\"A\"e2c ABc|\"D\"d2e fga|\n",
      "\"A7\"b\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "initial_index = np.random.randint(0, n_vocab, size=(1,))[0]\n",
    "music_abc = generate_sequence(model, vocab_map, initial_index=initial_index, seq_length=300)\n",
    "\n",
    "print(music_abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#header info: http://trillian.mit.edu/~jc/music/abc/doc/ABCtut_Headers.html#I_Key\n",
    "header = '''\n",
    "X: 1\n",
    "T:AbcRnn\n",
    "% abcRnn\n",
    "M:4/4\n",
    "K:K\n",
    "'''\n",
    "\n",
    "selected = '''\n",
    "^D/2A/2B/2A/2A F2F/2G/2|\n",
    "Aca aag|f/2a/2g/2f/2d/2 e3:|\n",
    "\\\n",
    "A/2g/2f/2g/2|\n",
    "f/2a3/2\n",
    "e/2A/2 f/2g/2g/2f/2d/2^G/2|\n",
    "\"D\"f2d/2d/2 \"Bm\"a3/2f/2a/2|\"Em\"g3 \"E7/c+\"e2d|\"A7/c+\"e2e \"F/f+\"d2c|\"Bm\"B2B A2^g|\n",
    "\"B7\"a2f f2f|\"E\"g2e \"B7\"B2d|\"B7\"e2f g2g|\"B7\"a3 a2f|\n",
    "\"D7\"d3 -c=cd|\"G\"B2G GBd|\"C\"e2e c2e|\"Am\"a3 \"G7\"g2d|\"C\"g3 z2:|\n",
    "P:C\n",
    "\n",
    "\n",
    "-----------------------------------------------------------------------------\n",
    "_ef|\"A\"a^ag \"D\"fed|\"F\"ecA \"G\"Bcd|\"Am\"e3 -\"D7\"d2||\n",
    "K:D\n",
    "\"D\"AFA \"G\"Bcd|\"D\"Adf \"G\"gab|\"D\"agf def|\"A7\"edc A2a|\"A7\"afd e2c|\n",
    "\"D\"d3 d2f|\"D\"A2f \"A/e\"c2e|\"Bm\"dcd \"E7\"e3|\"A\"cBc def|\n",
    "\"Bm\"dfB BcB|\"A\"cde \"E7\"e2A|[1\"A\"A3 -A2||\n",
    " [2\"A\"A3 A2G/2F/2|E/2A/2e/2 \"D\"dcd|\"A\"e3 e2c|\"A\"A3 -A7||\n",
    "K\n",
    "K:D\n",
    "\"D\"[2F2A \"A\"ABc|\"Bm\"d2d \"D\n",
    "'''\n",
    "\n",
    "selected = '''\n",
    "e|\"G\"d2e dBG|\"Am\"A2G \"D\"AFD|\"G\"G3 G2:|\n",
    "P:B\n",
    "d|\"G\"dBd def|\"C\"g2e \"A7\"e2e|\"D7\"f3 def|\"G\"g3 d2c|\"Am\"cdc \"D7\"A2c|\"G\"B2B B2e|\"Am\"d2d \"D7\"cBA|\"G\"G3 -G2||\n",
    "A|\"D\"\\\n",
    "FDF F2A|\"G\"BAG \"D\"FAd|\"A\"c3 \"F#m\"ABc|\"D\"d3 -d2||\n",
    "P:B\n",
    "A|\"D\"FGA FGA|\"D\"FAA def|\"G\"g3 -g2f|\"Em\"edB \"A7\"ABc|\n",
    "\"D\"d3 \"A7\"e3|\"D\"d3 d2c|\"A\"^cde A3|\"A\"^c2e \n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "music_abc = header + music_abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from music21 import *\n",
    "abcScore = converter.parse(music_abc, format='abc')\n",
    "mf = midi.translate.streamToMidiFile(abcScore)\n",
    "mf.open('.//midi_epoch20-03.mid', 'wb')\n",
    "mf.write()\n",
    "mf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cs478project)",
   "language": "python",
   "name": "cs478project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
